{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GeolifePrj_00_plt2df.ipynb**\n",
    ">## Convierte los .plt de **Geolife** a DataFrames de pandas y lo serializa\n",
    ">## \"Data\\\\xxx\\\\\\*\"   -->  \"geolife_xxx.zip\"  \n",
    ">## (=archivo pickle con un DataFrame y columnas ['time','lat','lon','lat','label','user'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os.path\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_plt(plt_file):\n",
    "    points = pd.read_csv(plt_file, skiprows=6, header=None,\n",
    "                         parse_dates=[[5, 6]], infer_datetime_format=True)\n",
    "\n",
    "    # for clarity rename columns\n",
    "    points.rename(inplace=True, columns={'5_6': 'time', 0: 'lat', 1: 'lon', 3: 'alt'})\n",
    "\n",
    "    # remove unused columns\n",
    "    points.drop(inplace=True, columns=[2, 4])\n",
    "\n",
    "    return points\n",
    "\n",
    "mode_names = ['walk', 'bike', 'bus', 'car', 'subway','train', 'airplane', 'boat', 'run', 'motorcycle', 'taxi']\n",
    "mode_ids = {s : i + 1 for i, s in enumerate(mode_names)}\n",
    "\n",
    "def read_labels(labels_file):\n",
    "    labels = pd.read_csv(labels_file, skiprows=1, header=None,\n",
    "                         parse_dates=[[0, 1], [2, 3]],\n",
    "                         infer_datetime_format=True, delim_whitespace=True)\n",
    "\n",
    "    # for clarity rename columns\n",
    "    labels.columns = ['start_time', 'end_time', 'label']\n",
    "\n",
    "    # replace 'label' column with integer encoding\n",
    "    labels['label'] = [mode_ids[i] for i in labels['label']]\n",
    "\n",
    "    return labels\n",
    "\n",
    "def apply_labels(points, labels):\n",
    "    indices = labels['start_time'].searchsorted(points['time'], side='right') - 1\n",
    "    no_label = (indices < 0) | (points['time'].values >= labels['end_time'].iloc[indices].values)\n",
    "    points['label'] = labels['label'].iloc[indices].values\n",
    "    points['label'][no_label] = 0\n",
    "\n",
    "def read_user(user_folder):\n",
    "    labels = None\n",
    "\n",
    "    plt_files = glob.glob(os.path.join(user_folder, 'Trajectory', '*.plt'))\n",
    "    df = pd.concat([read_plt(f) for f in plt_files])\n",
    "\n",
    "    labels_file = os.path.join(user_folder, 'labels.txt')\n",
    "    if os.path.exists(labels_file):\n",
    "        labels = read_labels(labels_file)\n",
    "        apply_labels(df, labels)\n",
    "    else:\n",
    "        df['label'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_all_users(folder):\n",
    "    subfolders = os.listdir(folder)\n",
    "    dfs = []\n",
    "    for i, sf in enumerate(subfolders):\n",
    "        print('[%d/%d] processing user %s' % (i + 1, len(subfolders), sf))\n",
    "        df = read_user(os.path.join(folder,sf))\n",
    "        df['user'] = int(sf)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readwrite_all_users(folder):\n",
    "    subfolders = os.listdir(folder)\n",
    "    dfs = []\n",
    "    for i, sf in enumerate(subfolders):\n",
    "        print('[%d/%d] processing user %s' % (i + 1, len(subfolders), sf), end=\" \")\n",
    "        df = read_user(os.path.join(folder,sf))\n",
    "        df['user'] = int(sf)\n",
    "        print(' ... escribiendo al disco...')\n",
    "        df.to_pickle('geolife_'+sf+'.zip')\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readwrite_all_users('Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **df** contiene TODA la data en UN SOLO dataframe: lo guardamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('geolife_all.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
